#! /usr/bin/env python3
# Get CVE data (vers 1.1) from NVD, load into CouchDB running on localhost
# To run CouchDB with docker:
# docker run -d -p 5984:5984 -e COUCHDB_USER=admin -e COUCHDB_PASSWORD=password --name couchdb couchdb

import requests, gzip, json, docker
from time2relax import CouchDB

# Main query template. Used for queries:
# 1. Count of Linux kernel CVEs by year range
#    $regex = 'linux_kernel'
#    publishedDate.$gte = start date
#    publishedDate.$lte = end date
# 2. Count of Linux kernel CVEs by
query_template = """
{
        "selector": {
          "configurations.nodes": {
            "$elemMatch": {
              "operator": "OR",
              "cpe_match": {
                "$elemMatch": {
                  "cpe23Uri": {
                    "$regex": "linux_kernel"
                  }
                }
              }
            }
          },
          "publishedDate": {
            "$gte": "YYYY-MM-DD",
            "$lte": "YYYY-MM-DD"
          }
        },
        "fields": [
          "cve.CVE_data_meta.ID"
        ],
        "limit": 999999
}
"""


def start_couchdb(name: str = 'couchdb', u: str = 'admin', p: str = 'password'):
    client = docker.from_env()
    return client.containers.run('couchdb', name=name, detach=True, auto_remove=True, environment=[f'COUCHDB_USER={u}', f'COUCHDB_PASSWORD={p}'], ports={'5984/tcp': 5984})


def make_batch(l, s):
    """
    Yields batch of size s from list l
    """
    for i in range(0, len(l), s):
        yield l[i : i + s]


def load_cve_data(url: str, db: CouchDB, start = 2002, end = 2023, vers: str = '1.1') -> None:
    """
    TODO end year default to current
    """
    for year in range(start, end):
        # TODO build url properly
        url_for_year = f'{url}/{vers}/nvdcve-{vers}-{year}.json.gz'
        batch_size = 100
        print(f'{year}..', end='', flush=True)

        r = requests.get(url_for_year)
        assert r.status_code == 200, 'Bad response code'
        assert r.headers['content-type'] == 'application/x-gzip', 'Bad content type'
        json_content = gzip.decompress(r.content)
        json_content_object = json.loads(json_content)
        for batch in make_batch(json_content_object['CVE_Items'], batch_size):
            db.bulk_docs(batch)
            # TODO Check success


if __name__ == '__main__':
    username = 'admin'
    password = 'password'
    docker_instance_name = 'couchdb_cve'

    print(f'Starting Docker instance "{docker_instance_name}"...', end='')
    couchdb_docker_container = start_couchdb(name=docker_instance_name, u=username, p=password)
    assert couchdb_docker_container.status == 'created', 'Docker failed'
    print('Done')

    # TODO Delete DB if already present?
    server = f'http://{username}:{password}@localhost:5984'
    database = 'nvd'
    nvd_url = "https://nvd.nist.gov/feeds/json/cve"
    sd = f'{server}/{database}'
    db = CouchDB(sd, create_db=True)

    print('Loading data...', end='', flush=True)
    load_cve_data(url=nvd_url, db=db)
    print('Done')

    print('Querying...')

    query = json.load(query_template)



    input('Press "Enter" to stop docker and finish')
    couchdb_docker_container.stop()
