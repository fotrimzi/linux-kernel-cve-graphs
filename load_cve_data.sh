#!/usr/bin/env bash
# - Download CVE data files from NVD
# - Unzip them
# - Start a CouchDB instance with Docker
# - Create a database called 'nvd'
# - Use couchimport to load them into the nvd database
# - Check the counts of downloaded and imported

#set -x

set -a

# Used by CouchDB
COUCHDB_USER="admin"
COUCHDB_PASSWORD="password"

# Used by couchimport
COUCH_URL="http://${COUCHDB_USER}:${COUCHDB_PASSWORD}@localhost:5984"
COUCH_DATABASE="nvd"
COUCH_FILETYPE="json"
COUCH_BUFFER_SIZE=100
COUCH_JSON_PATH="CVE_Items.*"

# Download URL (version 1.1)
VERS=1.1
NVD_URL="https://nvd.nist.gov/feeds/json/cve/${VERS}/"

function couchdb_start() {
    docker run -d -p 5984:5984 -e COUCHDB_USER=${COUCHDB_USER} -e COUCHDB_PASSWORD=${COUCHDB_PASSWORD} --name couchdb couchdb
}

function couchdb_stop {
    docker stop couchdb
    docker rm couchdb
}

function create_db() {
    curl -X PUT http://${COUCH_URL}${COUCH_DATABASE}
}

function download_cve_files() {
    FROM=${1:-2002}
    TO=${2:-$(date +%Y)}

    for YEAR in $(seq ${FROM} ${TO})
    do
        FILE=$(printf "nvdcve-${VERS}-%s.json.gz" $YEAR)
        URL="${NVD_URL}${FILE}"
        echo "Downloading ${URL} to ${FILE}"
        curl ${URL} --output ${FILE} --progress-bar --retry 10 && gunzip ${FILE}
    done
}

function import_cve_files() {
    for f in $(ls -1 nvdcve*.json); do
        echo "Importing ${f}"
        echo $COUCH_URL
        echo $COUCH_DELIMITER
        echo $COUCH_DATABASE
        echo $COUCH_FILETYPE
        echo $COUCH_JSON_PATH
        return
        cat ${f} | couchimport
    done
}

function count_downloaded_records() {
    grep CVE_data_numberOfCVEs nvdcve*.json | \
        cut -d':' -f3 | tr -cd '[:digit:][:cntrl:]' | \
        awk '{s+=$1} END {print s}'
}

function count_imported_records() {
    curl -sX GET ${COUCH_URL}/${COUCH_DATABASE} | jq '.doc_count'
}


#couchdb_start
#mkdir download
pushd download
#download_cve_files
import_cve_files
popd
#couchdb_stop
