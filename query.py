#! /usr/bin/env python3
# Query CVE data in CouchDB database and save results in files suitable for Gnuplot.

import argparse, datetime, json

# import couchdb # Deprecated https://github.com/djc/couchdb-python
# Use instead https://github.com/IBM/cloudant-python-sdk
from ibmcloudant.cloudant_v1 import CloudantV1
from ibm_cloud_sdk_core.authenticators import BasicAuthenticator
import pandas as pd # https://pandas.pydata.org/docs/

# Main query template
selector = { "configurations.nodes": { "$elemMatch": { "operator": "OR", "cpe_match": { "$elemMatch": { "cpe23Uri": { "$regex": "linux_kernel" } } } } }, "publishedDate": { "$gte": "2020-01-01", "$lte": "2023-12-31" } }

fields = [ "cve.CVE_data_meta.ID" ]

sort = []

limit = 999999

parser = argparse.ArgumentParser(
    prog='tba',
    description='Query CouchDB containing Linux kernel CVEs downloaded from NVD.')

parser.add_argument('--start', '-s', help='Start year (inclusive)', default=2002, type=int)
parser.add_argument('--end', '-e', help='End year (inclusive)',  default=datetime.datetime.now().year, type=int)
# parser.add_argument('--dbport', help='Local CouchDB port number', default='5984', type=int)
parser.add_argument('--dbuser', '-u', help='CouchDB admin username', default='admin')
parser.add_argument('--dbpass', '-p', help='CouchDB admin password', default='password')
parser.add_argument('--dbname', '-n', help='CouchDB database name', default='nvd')

global args
args = vars(parser.parse_args())


if __name__ == '__main__':

    server = f"http://{args['dbuser']}:{args['dbpass']}@localhost:5984"

    # WIP Must properly authenticate with IBMcloudant

    authenticator = BasicAuthenticator(f"{args['dbuser']}", f"{args['dbpass']}")
    service = CloudantV1(authenticator=authenticator)
    url = 'http://localhost:5984' # TODO use parameters
    service.set_service_url(f'{url}')
    #server_information = service.get_server_information().get_result()

    #print(f'Server Version: {server_information["version"]}')

    db_name = args['dbname']
    db_information = service.get_database_information(db=db_name).get_result()

    print(f"{db_information['doc_count']} items in database")

    data_to_plot = {}

    x_year = list()
    y_cves = list()

    # Run query separately for each year
    for year in range(args['start'], args['end']+1):

        # Adjust query params
        selector['configurations.nodes']['$elemMatch']['cpe_match']['$elemMatch']['cpe23Uri']['$regex'] = 'linux_kernel' # TODO Use this to add version
        selector['publishedDate']['$gte'] = f"{year!s}-01-01"
        selector['publishedDate']['$lte'] = f"{year!s}-12-31"
        #        print(qry)

        # Make the query
        print('Running query...')
        response = service.post_find(
            db=db_name,
            selector=selector,
            fields=fields,
            limit=limit
        ).get_result()

        #print(response['docs']) # TODO

        query_result_list = [r['cve']['CVE_data_meta']['ID'] for r in response['docs']]
        print(f'Result: {year}\t{len(query_result_list)}')

        x_year += [f'{year}']
        y_cves += [len(query_result_list)]

    # Use Panda df with Gnuplot
    df = pd.DataFrame({"cves": y_cves, "year": x_year})
    print(df)

    # TODO Save data as file

    # DataFrame.to_csv(path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression='infer', quoting=None, quotechar='"', lineterminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal='.', errors='strict', storage_options=None)

    # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html
    df.to_csv("test.csv")
